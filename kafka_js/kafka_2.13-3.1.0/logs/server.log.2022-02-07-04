[2022-02-07 04:46:36,171] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:46:36,175] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:46:36,177] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-02-07 04:46:36,187] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 5ms (kafka.server.KafkaServer)
[2022-02-07 04:46:36,190] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:46:36,190] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:46:36,190] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:46:36,190] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:46:36,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:46:36,195] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:46:36,195] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:46:36,197] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,298] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,298] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,299] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-02-07 04:46:36,302] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,476] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,476] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,481] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:46:36,483] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-02-07 04:46:36,483] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:46:36,483] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:46:36,483] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:46:36,485] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:46:36,486] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:36,487] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,528] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,528] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,529] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,658] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,658] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,658] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:36,664] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-02-07 04:46:36,665] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:46:36,665] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:46:36,665] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:46:36,665] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:46:36,666] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:46:36,667] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:46:36,667] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:46:36,667] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,864] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,864] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,865] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,928] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,928] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:36,928] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,080] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,080] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,081] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,128] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,128] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:37,148] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-02-07 04:46:37,149] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,149] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,149] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,158] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:46:37,159] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,159] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,159] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:37,160] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:46:37,160] INFO Shutting down. (kafka.log.LogManager)
[2022-02-07 04:46:37,175] INFO [ProducerStateManager partition=test-0] Wrote producer snapshot at offset 122 with 0 producer ids in 9 ms. (kafka.log.ProducerStateManager)
[2022-02-07 04:46:37,223] INFO [ProducerStateManager partition=__consumer_offsets-32] Wrote producer snapshot at offset 3 with 0 producer ids in 15 ms. (kafka.log.ProducerStateManager)
[2022-02-07 04:46:37,280] INFO Shutdown complete. (kafka.log.LogManager)
[2022-02-07 04:46:37,296] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:46:37,296] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:46:37,296] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:46:37,297] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:46:37,405] INFO Session: 0x1015bfe6af40000 closed (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:37,405] INFO EventThread shut down for session: 0x1015bfe6af40000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:37,406] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:46:37,406] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:37,718] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:37,718] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:37,718] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,718] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,718] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,718] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,720] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,720] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:38,720] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:39,720] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:39,720] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:39,723] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-02-07 04:46:39,736] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-02-07 04:46:39,736] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:46:39,736] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:46:39,736] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:46:39,737] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-02-07 04:46:39,738] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:46:39,738] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-02-07 04:46:52,462] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,463] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,465] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,465] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,465] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,465] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,466] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:46:52,466] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:46:52,467] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:46:52,467] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-02-07 04:46:52,469] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-02-07 04:46:52,477] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,477] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,478] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,478] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,478] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,478] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:46:52,478] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-02-07 04:46:52,488] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7f560810 (org.apache.zookeeper.server.ServerMetrics)
[2022-02-07 04:46:52,490] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:46:52,498] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,499] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:java.version=1.8.0_312 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,500] INFO Server environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.version=5.4.0-91-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.memory.free=492MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,502] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,503] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,503] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,503] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,503] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,504] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-02-07 04:46:52,505] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,505] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,505] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:46:52,506] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:46:52,506] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,506] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,507] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,507] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,507] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,507] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:46:52,508] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,508] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,508] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,514] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:46:52,515] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:46:52,515] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:46:52,518] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:46:52,528] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:46:52,528] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:46:52,528] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:46:52,528] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:46:52,535] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-02-07 04:46:52,536] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.bd (org.apache.zookeeper.server.persistence.FileSnap)
[2022-02-07 04:46:52,542] INFO The digest in the snapshot has digest version of 2, , with zxid as 0xbd, and digest value as 268875481875 (org.apache.zookeeper.server.DataTree)
[2022-02-07 04:46:52,557] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-02-07 04:46:52,557] INFO 31 txns loaded in 9 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:46:52,557] INFO Snapshot loaded in 28 ms, highest zxid is 0xdc, digest is 279933665780 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:46:52,557] INFO Snapshotting: 0xdc to /tmp/zookeeper/version-2/snapshot.dc (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:46:52,560] INFO Snapshot taken in 4 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:46:52,568] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-02-07 04:46:52,568] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-02-07 04:46:52,578] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-02-07 04:46:54,565] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-02-07 04:46:54,781] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-02-07 04:46:54,847] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:46:54,849] INFO starting (kafka.server.KafkaServer)
[2022-02-07 04:46:54,849] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-02-07 04:46:54,858] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:46:54,862] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,862] INFO Client environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,862] INFO Client environment:java.version=1.8.0_312 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,862] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,862] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,862] INFO Client environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:os.version=5.4.0-91-generic (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,863] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,864] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,864] INFO Client environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,864] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,864] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,864] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,865] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6b2ea799 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:46:54,868] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-02-07 04:46:54,872] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:54,873] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:46:54,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:54,875] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:54,877] INFO Socket connection established, initiating session, client: /127.0.0.1:50022, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:54,881] INFO Creating new log file: log.dd (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-02-07 04:46:54,895] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1015cae6ab90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:46:54,898] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:46:55,040] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:46:55,169] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-02-07 04:46:55,172] INFO Cluster ID = evk7zKJ8Ry6AlrJQfuz-RQ (kafka.server.KafkaServer)
[2022-02-07 04:46:55,203] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:46:55,209] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:46:55,232] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:55,233] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:55,233] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:55,234] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:46:55,261] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,263] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-02-07 04:46:55,326] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,340] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-18, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (1/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,357] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,358] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (2/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,381] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,383] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-31, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (3/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,405] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,407] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (4/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,425] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,429] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-7, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (5/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,449] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,453] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-42, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (6/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,473] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,480] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (7/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,503] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,510] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (8/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,538] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,545] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 34ms (9/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,584] INFO Deleted producer state snapshot /tmp/kafka-logs/__consumer_offsets-32/00000000000000000001.snapshot (kafka.log.SnapshotFile)
[2022-02-07 04:46:55,585] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,586] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,587] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-32/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-02-07 04:46:55,594] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,597] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-32, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 51ms (10/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,621] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,623] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-43, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (11/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,645] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,648] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (12/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,666] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,670] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (13/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,689] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,694] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-25, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (14/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,725] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,731] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-37, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (15/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,754] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,760] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-1, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (16/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,788] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,793] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 33ms (17/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,816] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,819] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (18/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,838] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,840] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (19/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,858] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,860] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-20, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (20/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,882] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,885] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (21/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,903] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,906] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (22/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,925] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,928] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (23/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,954] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,957] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-44, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (24/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:55,981] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:55,985] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-19, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (25/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,007] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,012] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-26, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (26/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,035] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,039] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (27/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,057] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,059] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (28/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,076] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,077] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (29/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,094] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,095] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-14, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (30/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,111] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,113] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (31/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,132] INFO Deleted producer state snapshot /tmp/kafka-logs/test-0/00000000000000000054.snapshot (kafka.log.SnapshotFile)
[2022-02-07 04:46:56,132] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,132] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,133] INFO [ProducerStateManager partition=test-0] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/test-0/00000000000000000122.snapshot,122)' (kafka.log.ProducerStateManager)
[2022-02-07 04:46:56,133] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,138] INFO Completed load of Log(dir=/tmp/kafka-logs/test-0, topicId=h4kZR_BXQDe0MInGs_hQ2A, topic=test, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=122) with 1 segments in 25ms (32/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,160] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,163] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-12, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (33/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,187] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,189] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-0, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (34/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,206] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,209] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (35/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,234] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,238] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-6, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (36/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,261] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,266] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-8, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (37/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,287] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,289] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-24, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (38/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,311] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,315] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (39/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,336] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,341] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (40/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,362] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,366] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (41/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,387] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,391] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-48, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (42/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,412] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,416] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (43/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,437] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,441] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-38, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (44/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,470] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,474] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-49, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (45/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,516] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,518] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-36, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 45ms (46/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,538] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,541] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (47/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,565] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,568] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-2, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (48/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,588] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,591] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-13, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (49/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,614] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,617] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-30, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (50/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,637] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:46:56,640] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=8NyYGvF9QNe6CTMyRgiwOA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (51/51 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:46:56,643] INFO Loaded 51 logs in 1382ms. (kafka.log.LogManager)
[2022-02-07 04:46:56,644] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-02-07 04:46:56,645] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-02-07 04:46:56,882] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:56,970] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-02-07 04:46:56,972] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-02-07 04:46:56,990] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:46:56,995] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:57,008] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,008] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,009] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,009] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,018] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:46:57,050] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-02-07 04:46:57,078] INFO Stat of the created znode at /brokers/ids/0 is: 236,236,1644209217067,1644209217067,1,0,0,72440973199212544,208,0,236
 (kafka.zk.KafkaZkClient)
[2022-02-07 04:46:57,078] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://6f09ab0dc5f0:9092, czxid (broker epoch): 236 (kafka.zk.KafkaZkClient)
[2022-02-07 04:46:57,131] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,135] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,135] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,148] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:57,157] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:57,170] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:46:57,174] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:46:57,176] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:46:57,206] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:46:57,225] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:46:57,242] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-02-07 04:46:57,253] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:46:57,254] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-02-07 04:46:57,256] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:46:57,256] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:46:57,256] INFO Kafka startTimeMs: 1644209217254 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:46:57,257] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-02-07 04:46:57,287] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker 6f09ab0dc5f0:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:57,296] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker 6f09ab0dc5f0:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:46:57,313] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, test-0, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:46:57,319] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,341] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,362] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,377] INFO [Partition test-0 broker=0] Log loaded for partition test-0 with initial high watermark 122 (kafka.cluster.Partition)
[2022-02-07 04:46:57,377] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,391] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,406] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,420] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,439] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,454] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,469] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,483] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,498] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,513] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,534] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,548] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,568] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,588] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,605] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,621] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,638] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,654] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,671] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,691] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,713] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,730] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Partition)
[2022-02-07 04:46:57,731] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,747] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,764] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,786] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,802] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,825] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,841] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,857] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,873] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,889] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,906] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,922] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,939] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,956] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:57,995] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,013] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,029] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,044] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,069] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,085] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,101] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,117] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,134] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,150] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,166] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:46:58,201] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,214] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,214] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,214] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,219] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,219] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,219] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,219] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,220] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,220] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,220] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,220] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,220] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,221] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,221] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,221] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:46:58,221] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 17 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,229] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,229] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,229] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,229] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,230] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,250] INFO Loaded member MemberMetadata(memberId=console-consumer-5b6d7fe8-2bd6-4111-b3ae-7681cb5bc11a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.19.0.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-99995 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 38 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 38 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 38 milliseconds for epoch 0, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,255] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 37 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 36 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,256] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 36 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 37 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 37 milliseconds for epoch 0, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 36 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:46:58,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 36 milliseconds for epoch 0, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:51:34,275] WARN Unexpected exception (org.apache.zookeeper.server.NIOServerCnxn)
EndOfStreamException: Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:50026, session = 0x1015cae6ab90001
	at org.apache.zookeeper.server.NIOServerCnxn.handleFailedRead(NIOServerCnxn.java:163)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:326)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-02-07 04:51:36,452] WARN Session 0x1015cae6ab90000 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1015cae6ab90000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-02-07 04:51:37,605] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:51:37,607] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:51:37,609] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-02-07 04:51:37,620] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 6ms (kafka.server.KafkaServer)
[2022-02-07 04:51:37,622] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:51:37,623] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:51:37,623] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:51:37,623] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:51:37,626] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:51:37,627] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:51:37,628] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:51:37,629] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,801] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,801] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,803] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-02-07 04:51:37,806] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,926] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,926] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:37,931] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:51:37,933] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-02-07 04:51:37,933] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:51:37,933] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:51:37,933] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:51:37,934] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:51:37,936] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:51:37,937] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,128] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,128] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,129] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,210] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:51:38,210] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:51:38,211] WARN Session 0x1015cae6ab90000 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-02-07 04:51:38,328] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,328] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,330] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:51:38,331] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-02-07 04:51:38,332] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:51:38,332] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:51:38,332] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:51:38,333] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:51:38,334] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:51:38,334] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:51:38,335] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:51:38,335] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,431] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,431] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,432] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,602] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,602] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,602] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,800] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,800] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:38,800] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:39,001] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:39,001] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:51:39,026] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-02-07 04:51:39,027] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,027] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,028] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,033] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:51:39,033] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,033] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,033] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:51:39,033] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:51:39,033] INFO Shutting down. (kafka.log.LogManager)
[2022-02-07 04:51:39,085] INFO Shutdown complete. (kafka.log.LogManager)
[2022-02-07 04:51:39,088] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:51:39,089] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:51:39,089] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:51:39,089] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:51:39,877] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:51:39,877] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:51:39,878] WARN An exception was thrown while closing send thread for session 0x1015cae6ab90000. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-02-07 04:51:39,981] INFO Session: 0x1015cae6ab90000 closed (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:51:39,981] INFO EventThread shut down for session: 0x1015cae6ab90000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:51:39,983] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:51:39,984] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:40,272] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:40,272] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:40,272] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,272] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,272] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,272] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,273] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,273] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:41,273] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:42,272] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:42,272] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:51:42,275] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-02-07 04:51:42,287] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-02-07 04:51:42,288] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:51:42,288] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:51:42,288] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:51:42,289] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-02-07 04:51:42,289] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:51:42,289] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-02-07 04:53:53,484] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,485] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,487] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,487] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,487] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,488] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,489] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:53:53,489] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:53:53,489] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:53:53,489] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-02-07 04:53:53,491] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-02-07 04:53:53,498] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,498] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,499] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,499] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,499] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,499] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:53:53,499] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-02-07 04:53:53,507] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7f560810 (org.apache.zookeeper.server.ServerMetrics)
[2022-02-07 04:53:53,510] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:53:53,516] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,516] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,516] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,516] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,516] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,517] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,517] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,517] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,517] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,517] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:java.version=1.8.0_312 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,518] INFO Server environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,519] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,519] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,519] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,519] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,519] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:os.version=5.4.0-91-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:os.memory.free=492MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,520] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,521] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-02-07 04:53:53,522] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,522] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,523] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:53:53,523] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,524] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:53:53,525] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,525] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,525] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,530] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:53:53,531] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:53:53,532] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:53:53,535] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:53:53,545] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:53:53,545] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:53:53,545] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:53:53,545] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:53:53,550] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-02-07 04:53:53,551] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.dc (org.apache.zookeeper.server.persistence.FileSnap)
[2022-02-07 04:53:53,557] INFO The digest in the snapshot has digest version of 2, , with zxid as 0xdc, and digest value as 279933665780 (org.apache.zookeeper.server.DataTree)
[2022-02-07 04:53:53,568] INFO 20 txns loaded in 7 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:53:53,568] INFO Snapshot loaded in 24 ms, highest zxid is 0xf0, digest is 271029056786 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:53:53,569] INFO Snapshotting: 0xf0 to /tmp/zookeeper/version-2/snapshot.f0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:53:53,571] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:53:53,579] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-02-07 04:53:53,579] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-02-07 04:53:53,588] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-02-07 04:53:53,589] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-02-07 04:53:57,732] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-02-07 04:53:57,951] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-02-07 04:53:58,018] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:53:58,021] INFO starting (kafka.server.KafkaServer)
[2022-02-07 04:53:58,021] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-02-07 04:53:58,030] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:53:58,034] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,034] INFO Client environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,034] INFO Client environment:java.version=1.8.0_312 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,034] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,034] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,034] INFO Client environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:os.version=5.4.0-91-generic (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,035] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,036] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,036] INFO Client environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,036] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,036] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,036] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,037] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6b2ea799 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:58,040] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-02-07 04:53:58,044] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:58,045] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:53:58,046] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:58,046] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:58,049] INFO Socket connection established, initiating session, client: /127.0.0.1:50056, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:58,053] INFO Creating new log file: log.f1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-02-07 04:53:58,080] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1015cb4d74c0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:58,087] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:53:58,194] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:53:58,323] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-02-07 04:53:58,326] INFO Cluster ID = evk7zKJ8Ry6AlrJQfuz-RQ (kafka.server.KafkaServer)
[2022-02-07 04:53:58,328] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-02-07 04:53:58,357] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:53:58,363] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:53:58,386] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:53:58,386] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:53:58,387] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:53:58,387] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:53:58,413] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:53:58,416] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-02-07 04:53:58,481] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:53:58,481] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:53:58,482] INFO [ProducerStateManager partition=test-0] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/test-0/00000000000000000122.snapshot,122)' (kafka.log.ProducerStateManager)
[2022-02-07 04:53:58,486] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:53:58,499] INFO Completed load of Log(dir=/tmp/kafka-logs/test-0, topicId=h4kZR_BXQDe0MInGs_hQ2A, topic=test, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=122) with 1 segments in 76ms (1/1 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:53:58,500] INFO Loaded 1 logs in 87ms. (kafka.log.LogManager)
[2022-02-07 04:53:58,501] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-02-07 04:53:58,501] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-02-07 04:53:58,724] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:58,831] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-02-07 04:53:58,833] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-02-07 04:53:58,854] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:53:58,859] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:58,879] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:58,880] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:58,880] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:58,881] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:58,889] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:53:58,925] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-02-07 04:53:58,943] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72440973199212544' does not match current session '72441000790589440' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-02-07 04:53:58,947] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-02-07 04:53:58,948] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:53:58,949] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:53:58,950] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:53:58,952] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-02-07 04:53:58,953] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:53:58,953] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:53:58,953] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:53:58,953] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:53:58,960] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:53:58,960] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:53:58,960] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:53:58,960] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,080] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,080] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,080] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,279] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,280] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,281] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,481] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,481] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,482] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,681] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,681] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:53:59,690] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-02-07 04:53:59,690] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,690] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,690] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,694] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:53:59,694] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,694] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,694] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:53:59,694] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:53:59,694] INFO Shutting down. (kafka.log.LogManager)
[2022-02-07 04:53:59,750] INFO Shutdown complete. (kafka.log.LogManager)
[2022-02-07 04:53:59,750] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:53:59,750] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:53:59,750] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:53:59,751] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:53:59,859] INFO Session: 0x1015cb4d74c0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:53:59,859] INFO EventThread shut down for session: 0x1015cb4d74c0000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:53:59,862] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:53:59,863] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:00,386] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:00,387] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:00,387] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:01,387] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:01,387] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:01,388] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:02,388] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:02,388] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:02,388] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:03,389] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:03,389] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:03,392] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-02-07 04:54:03,413] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-02-07 04:54:03,413] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:03,413] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:03,413] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:03,415] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-02-07 04:54:03,417] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:54:03,417] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-02-07 04:54:03,417] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-02-07 04:54:03,417] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:54:09,067] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-02-07 04:54:09,282] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-02-07 04:54:09,346] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:54:09,348] INFO starting (kafka.server.KafkaServer)
[2022-02-07 04:54:09,349] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-02-07 04:54:09,359] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:09,364] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,364] INFO Client environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,364] INFO Client environment:java.version=1.8.0_312 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,364] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,364] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,364] INFO Client environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.version=5.4.0-91-generic (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,366] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,368] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6b2ea799 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:09,371] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-02-07 04:54:09,375] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:09,376] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:09,378] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:09,378] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:09,380] INFO Socket connection established, initiating session, client: /127.0.0.1:50060, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:09,388] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1015cb4d74c0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:09,390] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:09,511] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:54:09,648] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-02-07 04:54:09,651] INFO Cluster ID = evk7zKJ8Ry6AlrJQfuz-RQ (kafka.server.KafkaServer)
[2022-02-07 04:54:09,653] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-02-07 04:54:09,685] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:54:09,691] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:54:09,716] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:09,716] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:09,717] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:09,718] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:09,742] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:54:09,745] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-02-07 04:54:09,809] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:09,810] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:09,811] INFO [ProducerStateManager partition=test-0] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/test-0/00000000000000000122.snapshot,122)' (kafka.log.ProducerStateManager)
[2022-02-07 04:54:09,814] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:09,827] INFO Completed load of Log(dir=/tmp/kafka-logs/test-0, topicId=h4kZR_BXQDe0MInGs_hQ2A, topic=test, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=122) with 1 segments in 75ms (1/1 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:54:09,829] INFO Loaded 1 logs in 87ms. (kafka.log.LogManager)
[2022-02-07 04:54:09,829] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-02-07 04:54:09,829] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-02-07 04:54:10,049] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:10,158] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-02-07 04:54:10,161] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-02-07 04:54:10,182] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:54:10,187] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:10,205] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,206] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,206] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,207] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,215] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:54:10,252] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-02-07 04:54:10,267] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72440973199212544' does not match current session '72441000790589441' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-02-07 04:54:10,271] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-02-07 04:54:10,273] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:54:10,273] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:54:10,275] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:54:10,276] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-02-07 04:54:10,277] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:54:10,277] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:54:10,277] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:54:10,278] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:54:10,284] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:54:10,284] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:54:10,284] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:54:10,284] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,406] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,406] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,406] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,606] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,606] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,607] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,807] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,807] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:10,808] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:11,007] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:11,007] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:11,024] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-02-07 04:54:11,025] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,026] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,026] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,042] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:54:11,043] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,043] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,043] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:11,044] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:54:11,045] INFO Shutting down. (kafka.log.LogManager)
[2022-02-07 04:54:11,112] INFO Shutdown complete. (kafka.log.LogManager)
[2022-02-07 04:54:11,114] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:54:11,114] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:54:11,114] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:54:11,116] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:11,227] INFO Session: 0x1015cb4d74c0001 closed (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:11,227] INFO EventThread shut down for session: 0x1015cb4d74c0001 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:11,230] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:11,231] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:11,717] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:11,717] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:11,717] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:12,717] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:12,717] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:12,718] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:12,810] INFO Expiring session 0x1015cae6ab90000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:13,718] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:13,718] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:13,718] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:14,719] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:14,719] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:14,722] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-02-07 04:54:14,746] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-02-07 04:54:14,746] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:14,746] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:14,747] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:54:14,748] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-02-07 04:54:14,749] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:54:14,750] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-02-07 04:54:14,750] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-02-07 04:54:14,750] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:54:28,082] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,083] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,085] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,086] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,086] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,086] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,087] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:54:28,087] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:54:28,087] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-02-07 04:54:28,087] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-02-07 04:54:28,089] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-02-07 04:54:28,096] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,096] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,097] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,097] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,097] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,097] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-02-07 04:54:28,097] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-02-07 04:54:28,105] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7f560810 (org.apache.zookeeper.server.ServerMetrics)
[2022-02-07 04:54:28,108] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:54:28,114] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,114] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,114] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,114] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,114] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,114] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,115] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,115] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,115] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,115] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:java.version=1.8.0_312 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,116] INFO Server environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,117] INFO Server environment:os.version=5.4.0-91-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:os.memory.free=492MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,118] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,119] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-02-07 04:54:28,120] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,120] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,121] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:54:28,121] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-02-07 04:54:28,121] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,121] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,122] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,122] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,122] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,122] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-02-07 04:54:28,123] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,123] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,123] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,128] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:54:28,129] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-02-07 04:54:28,130] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:54:28,133] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-02-07 04:54:28,143] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:54:28,143] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-02-07 04:54:28,143] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:54:28,143] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:54:28,149] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-02-07 04:54:28,149] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.f0 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-02-07 04:54:28,155] INFO The digest in the snapshot has digest version of 2, , with zxid as 0xf0, and digest value as 271029056786 (org.apache.zookeeper.server.DataTree)
[2022-02-07 04:54:28,166] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-02-07 04:54:28,166] INFO 35 txns loaded in 7 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:54:28,166] INFO Snapshot loaded in 23 ms, highest zxid is 0x113, digest is 268885179695 (org.apache.zookeeper.server.ZKDatabase)
[2022-02-07 04:54:28,166] INFO Snapshotting: 0x113 to /tmp/zookeeper/version-2/snapshot.113 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-02-07 04:54:28,169] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:54:28,176] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-02-07 04:54:28,176] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-02-07 04:54:28,186] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-02-07 04:54:32,739] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-02-07 04:54:32,954] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-02-07 04:54:33,019] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:54:33,021] INFO starting (kafka.server.KafkaServer)
[2022-02-07 04:54:33,021] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-02-07 04:54:33,031] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:33,034] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,034] INFO Client environment:host.name=6f09ab0dc5f0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,034] INFO Client environment:java.version=1.8.0_312 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,034] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,034] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,034] INFO Client environment:java.class.path=/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/workspace/kafka_js/kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.version=5.4.0-91-generic (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:user.dir=/home/workspace/kafka_js/kafka_2.13-3.1.0 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,036] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,038] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6b2ea799 (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:54:33,040] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-02-07 04:54:33,044] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:33,045] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:33,047] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:33,047] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:33,049] INFO Socket connection established, initiating session, client: /127.0.0.1:50062, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:33,054] INFO Creating new log file: log.114 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-02-07 04:54:33,067] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1015cb55e720000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:54:33,070] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:54:33,216] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:54:33,355] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-02-07 04:54:33,358] INFO Cluster ID = evk7zKJ8Ry6AlrJQfuz-RQ (kafka.server.KafkaServer)
[2022-02-07 04:54:33,360] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-02-07 04:54:33,389] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:54:33,394] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-02-07 04:54:33,418] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:33,418] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:33,418] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:33,419] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:54:33,444] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:54:33,447] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-02-07 04:54:33,515] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Loading producer state till offset 122 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:33,515] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:33,516] INFO [ProducerStateManager partition=test-0] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/test-0/00000000000000000122.snapshot,122)' (kafka.log.ProducerStateManager)
[2022-02-07 04:54:33,519] INFO [LogLoader partition=test-0, dir=/tmp/kafka-logs] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 122 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:33,533] INFO Completed load of Log(dir=/tmp/kafka-logs/test-0, topicId=h4kZR_BXQDe0MInGs_hQ2A, topic=test, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=122) with 1 segments in 78ms (1/1 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-02-07 04:54:33,534] INFO Loaded 1 logs in 90ms. (kafka.log.LogManager)
[2022-02-07 04:54:33,534] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-02-07 04:54:33,535] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-02-07 04:54:33,752] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:33,855] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-02-07 04:54:33,858] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-02-07 04:54:33,878] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:54:33,882] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:33,903] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:33,903] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:33,904] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:33,904] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:33,913] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:54:33,947] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-02-07 04:54:33,969] INFO Stat of the created znode at /brokers/ids/0 is: 291,291,1644209673958,1644209673958,1,0,0,72441003058003968,208,0,291
 (kafka.zk.KafkaZkClient)
[2022-02-07 04:54:33,969] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://6f09ab0dc5f0:9092, czxid (broker epoch): 291 (kafka.zk.KafkaZkClient)
[2022-02-07 04:54:34,030] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:34,034] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:34,035] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:34,053] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:34,064] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:34,081] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:54:34,090] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:54:34,090] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:54:34,120] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:54:34,141] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:54:34,154] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-02-07 04:54:34,162] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-02-07 04:54:34,162] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-02-07 04:54:34,164] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:54:34,164] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:54:34,164] INFO Kafka startTimeMs: 1644209674162 (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:54:34,165] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-02-07 04:54:34,185] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker 6f09ab0dc5f0:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:34,214] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:54:34,225] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,227] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,228] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-02-07 04:54:34,229] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,257] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker 6f09ab0dc5f0:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:54:34,259] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,259] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,259] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-02-07 04:54:34,259] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,289] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,290] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,290] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-02-07 04:54:34,290] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,329] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,329] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,329] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-02-07 04:54:34,329] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,364] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,365] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,365] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-02-07 04:54:34,365] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,397] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,399] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,399] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-02-07 04:54:34,399] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,436] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,438] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,438] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-02-07 04:54:34,439] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,474] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,476] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,477] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-02-07 04:54:34,477] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,539] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,542] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,542] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-02-07 04:54:34,542] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,584] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,586] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,586] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-02-07 04:54:34,586] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,631] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,634] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,634] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-02-07 04:54:34,634] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,671] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,674] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,674] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-02-07 04:54:34,674] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,711] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,713] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,714] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-02-07 04:54:34,714] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,751] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,754] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,754] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-02-07 04:54:34,755] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,793] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,795] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,796] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-02-07 04:54:34,796] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,837] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,840] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,841] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-02-07 04:54:34,841] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,876] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,879] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,879] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-02-07 04:54:34,879] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,913] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,914] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,915] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-02-07 04:54:34,915] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,951] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,953] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,953] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-02-07 04:54:34,953] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:34,990] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:34,991] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:34,991] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-02-07 04:54:34,991] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,020] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,020] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,020] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-02-07 04:54:35,020] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,054] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,055] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,055] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-02-07 04:54:35,055] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,092] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,094] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,094] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-02-07 04:54:35,095] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,133] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,135] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,136] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-02-07 04:54:35,136] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,172] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,173] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,173] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-02-07 04:54:35,173] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,209] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,210] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,210] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-02-07 04:54:35,211] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,257] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,259] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,260] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-02-07 04:54:35,260] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,295] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,297] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,298] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-02-07 04:54:35,298] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,343] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,345] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,346] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-02-07 04:54:35,346] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,377] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,378] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,378] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-02-07 04:54:35,378] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,409] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,409] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,409] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-02-07 04:54:35,410] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,444] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,446] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,446] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-02-07 04:54:35,447] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,482] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,484] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,484] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-02-07 04:54:35,485] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,522] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,523] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,523] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-02-07 04:54:35,523] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,553] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,554] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,554] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-02-07 04:54:35,554] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,589] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,591] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,591] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-02-07 04:54:35,592] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,629] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,631] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,631] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-02-07 04:54:35,631] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,673] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,674] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,675] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,675] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,710] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,712] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,712] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-02-07 04:54:35,712] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,747] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,749] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,750] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-02-07 04:54:35,750] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,786] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,788] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,788] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-02-07 04:54:35,788] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,828] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,830] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,830] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-02-07 04:54:35,830] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,865] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,867] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,867] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-02-07 04:54:35,867] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,902] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,904] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,904] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-02-07 04:54:35,905] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,949] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,950] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,951] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-02-07 04:54:35,951] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:35,985] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:35,987] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:35,988] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-02-07 04:54:35,988] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:36,027] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:36,029] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:36,029] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-02-07 04:54:36,030] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:36,070] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:36,072] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:36,072] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-02-07 04:54:36,072] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:36,107] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:36,110] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:36,110] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-02-07 04:54:36,110] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:36,151] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-02-07 04:54:36,153] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-02-07 04:54:36,153] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-02-07 04:54:36,153] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-02-07 04:54:36,198] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,205] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,205] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,205] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,205] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,210] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,214] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:54:36,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 14 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 13 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 13 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 13 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 13 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:36,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-02-07 04:54:56,896] INFO Creating topic test with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-02-07 04:55:00,809] INFO Expiring session 0x1015cae6ab90001, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-02-07 04:57:18,736] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-02-07 04:57:18,737] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-02-07 04:57:18,738] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-02-07 04:57:18,748] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 6ms (kafka.server.KafkaServer)
[2022-02-07 04:57:18,752] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:57:18,752] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:57:18,752] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-02-07 04:57:18,753] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:57:18,757] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-02-07 04:57:18,758] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:57:18,759] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-02-07 04:57:18,760] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,801] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,801] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,801] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-02-07 04:57:18,802] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,895] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,895] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:18,900] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:57:18,901] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-02-07 04:57:18,901] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:57:18,902] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:57:18,902] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-02-07 04:57:18,903] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-02-07 04:57:18,904] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:57:18,905] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,097] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,097] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,098] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,297] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,297] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,298] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-02-07 04:57:19,300] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-02-07 04:57:19,301] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:57:19,301] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:57:19,301] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-02-07 04:57:19,303] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:57:19,306] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-02-07 04:57:19,307] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:57:19,307] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-02-07 04:57:19,307] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,367] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,367] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,368] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,568] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,568] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,568] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,768] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,768] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,768] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,968] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,968] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-02-07 04:57:19,988] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-02-07 04:57:19,989] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,989] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,989] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,995] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:57:19,995] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,995] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,995] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-02-07 04:57:19,995] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-02-07 04:57:19,995] INFO Shutting down. (kafka.log.LogManager)
[2022-02-07 04:57:20,059] INFO Shutdown complete. (kafka.log.LogManager)
[2022-02-07 04:57:20,075] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:57:20,075] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:57:20,075] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-02-07 04:57:20,077] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:57:20,188] INFO Session: 0x1015cb55e720000 closed (org.apache.zookeeper.ZooKeeper)
[2022-02-07 04:57:20,188] INFO EventThread shut down for session: 0x1015cb55e720000 (org.apache.zookeeper.ClientCnxn)
[2022-02-07 04:57:20,191] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-02-07 04:57:20,191] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:20,431] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:20,431] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:20,432] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:21,431] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:21,431] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:21,432] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,432] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,432] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,432] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,432] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,432] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-02-07 04:57:22,435] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-02-07 04:57:22,447] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-02-07 04:57:22,447] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:57:22,447] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:57:22,447] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-02-07 04:57:22,448] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-02-07 04:57:22,449] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-02-07 04:57:22,449] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
